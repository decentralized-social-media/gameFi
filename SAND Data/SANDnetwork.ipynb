{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from bisect import bisect_left\n",
    "import pandas as pd\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "filePath = \"./files/\"\n",
    "\n",
    "\n",
    "def get_valid_filename(name):\n",
    "    s = str(name).strip().replace(\" \", \"_\")\n",
    "    s = re.sub(r\"(?u)[^-\\w.]\", \"\", s)\n",
    "    if s in {\"\", \".\", \"..\"}:\n",
    "        return \"ErrorFileName\" + str(random.randrange(100000))\n",
    "    return s\n",
    "\n",
    "\n",
    "def get_valid_path(path):\n",
    "    s = str(path).strip().replace(\" \", \"_\")\n",
    "    s = re.sub(r\"(?u)[^-\\w./]\", \"\", s)\n",
    "    if s in {\"\", \".\", \"..\"}:\n",
    "        return \"ErrorFileName\" + str(random.randrange(100000))\n",
    "    return s\n",
    "\n",
    "\n",
    "def loadJSON(fullFileName):\n",
    "    if not os.path.exists(fullFileName):\n",
    "        return {}\n",
    "    with open(fullFileName, \"r\") as inputFile:\n",
    "        data = json.load(inputFile)\n",
    "    return data\n",
    "\n",
    "\n",
    "def dumpFile(fileName, data, path=filePath):\n",
    "    fullFileName = get_valid_path(path) + get_valid_filename(fileName) + \".bin\"\n",
    "    os.makedirs(os.path.dirname(fullFileName), exist_ok=True)\n",
    "    with open(fullFileName, \"wb\") as outputFile:\n",
    "        pickle.dump(data, outputFile)\n",
    "    return fullFileName\n",
    "\n",
    "\n",
    "def checkForFile(filename):\n",
    "    return os.path.exists(filePath + get_valid_filename(filename) + \".bin\")\n",
    "\n",
    "\n",
    "def loadFile(fileName):\n",
    "    fullFileName = filePath + get_valid_filename(fileName) + \".bin\"\n",
    "    if not os.path.exists(fullFileName):\n",
    "        return {}\n",
    "    with open(fullFileName, \"rb\") as inputFile:\n",
    "        data = pickle.load(inputFile)\n",
    "    return data\n",
    "\n",
    "\n",
    "def saveOrLoadFile(fileName, fileFunction, functionParams={}):\n",
    "    if checkForFile(fileName):\n",
    "        return loadFile(fileName)\n",
    "    else:\n",
    "        fileData = fileFunction(**functionParams)\n",
    "        dumpFile(fileName, fileData)\n",
    "        return fileData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSimplifiedData():\n",
    "    dataFiles = []\n",
    "\n",
    "    dirpath = \"./data\"\n",
    "    for root, dirs, files in os.walk(dirpath):\n",
    "        for name in files:\n",
    "            dataFiles.append(os.path.join(root, name))\n",
    "\n",
    "    data = []\n",
    "    for dataFile in dataFiles:\n",
    "        data.extend(loadJSON(dataFile))\n",
    "\n",
    "    simplifiedData = [\n",
    "        {\n",
    "            \"Source\": d.get(\"from\"),\n",
    "            \"Target\": d.get(\"to\") if d.get(\"to\") != \"\" else d.get(\"contractAddress\"),\n",
    "            \"Timeset\": datetime.fromtimestamp(int(d.get(\"timeStamp\"))).isoformat(),\n",
    "            \"Weight\": int(d.get(\"value\") if d.get(\"value\") is not None else 0) + 1,\n",
    "            \"Contract\": d.get(\"contractAddress\"),\n",
    "        }\n",
    "        for d in data\n",
    "    ]\n",
    "\n",
    "    return simplifiedData\n",
    "\n",
    "\n",
    "simplifiedData = saveOrLoadFile(\n",
    "    fileName=\"simplifiedData\", fileFunction=generateSimplifiedData\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterSimplifiedData(\n",
    "    data, minTime=None, maxTime=None, minWeight=None, maxWeight=None, contract=None\n",
    "):\n",
    "    filteredData = filter(\n",
    "        lambda dataPoint: (\n",
    "            (minTime is None or dataPoint[\"Timeset\"] >= minTime)\n",
    "            and (maxTime is None or dataPoint[\"TimeSet\"] <= maxTime)\n",
    "            and (minWeight is None or dataPoint[\"Weight\"] >= minWeight)\n",
    "            and (maxWeight is None or dataPoint[\"Weight\"] <= maxWeight)\n",
    "            and (contract is None or dataPoint[\"Contract\"] == contract)\n",
    "        ),\n",
    "        data,\n",
    "    )\n",
    "\n",
    "    return list(filteredData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def makeGraphFile(data):\n",
    "#     keys = data[0].keys()\n",
    "#     fileName = \"SANDgraph\" +\".csv\"\n",
    "#     with open(fileName, 'w', newline='') as output_file:\n",
    "#         dict_writer = csv.DictWriter(output_file, keys)\n",
    "#         dict_writer.writeheader()\n",
    "#         dict_writer.writerows(data)\n",
    "\n",
    "# makeGraphFile(random.sample(simplifiedData, 400000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataGraph():\n",
    "    dataGraph = nx.MultiDiGraph()\n",
    "    for simplifiedDataPoint in simplifiedData:\n",
    "        dataGraph.add_edge(\n",
    "            simplifiedDataPoint[\"Source\"],\n",
    "            simplifiedDataPoint[\"Target\"]\n",
    "            if simplifiedDataPoint[\"Target\"] != \"\"\n",
    "            else simplifiedDataPoint[\"Contract\"],\n",
    "            key=simplifiedDataPoint[\"Timeset\"],\n",
    "            attr={\n",
    "                \"Timeset\": simplifiedDataPoint[\"Timeset\"],\n",
    "                \"Weight\": simplifiedDataPoint[\"Weight\"],\n",
    "                \"Contract\": simplifiedDataPoint[\"Contract\"],\n",
    "            },\n",
    "        )\n",
    "    return dataGraph\n",
    "\n",
    "\n",
    "dataGraph = saveOrLoadFile(\"graphData\", generateDataGraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1191\n"
     ]
    }
   ],
   "source": [
    "def getSandValueData():\n",
    "    with open(\"sandboxValueData.csv\", \"r\") as inputFile:\n",
    "        sandValueData = csv.DictReader(inputFile)\n",
    "        sandValueData = [{d[\"\\ufeffStart\"]: d[\"Market Cap\"]} for d in sandValueData]\n",
    "    return sandValueData\n",
    "\n",
    "sandValueData = saveOrLoadFile(\"sandValueData\", getSandValueData)\n",
    "print(len(sandValueData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/jeroenvldj/bow-tie_detection/tree/master\n",
    "\n",
    "\n",
    "def get_bowtie_components(graph):\n",
    "    \"\"\"Classifying the nodes of a network into a bow-tie structure.\n",
    "    Here we follow the definition of a bow-tie as in:\n",
    "    \"Bow-tie Decomposition in Directed Graphs\" - Yang et al. IEEE (2011)\n",
    "\n",
    "    input:  NetworkX directed graph or numpy adjacency matrix\n",
    "    output: sets of nodes in the specified partitions (following the\n",
    "            NetworkX input graph node labelling or labelled according to\n",
    "            the order of the adjacency matrix [0, n-1])\n",
    "    \"\"\"\n",
    "\n",
    "    # Verify graph input format\n",
    "    input_formats = [nx.DiGraph, nx.MultiDiGraph, np.ndarray, np.matrix]\n",
    "    assert (\n",
    "        type(graph) in input_formats\n",
    "    ), \"Input should be a NetworkX directed graph or numpy adjacency matrix\"\n",
    "    if (\n",
    "        type(graph) == nx.classes.digraph.DiGraph\n",
    "        or type(graph) == nx.classes.multidigraph.MultiDiGraph\n",
    "    ):\n",
    "        G = graph.copy()\n",
    "    if (type(graph) == np.ndarray) or (type(graph) == np.matrix):\n",
    "        G = nx.from_numpy_matrix(np.matrix(graph), create_using=nx.DiGraph())\n",
    "\n",
    "    GT = nx.reverse(G, copy=True)\n",
    "\n",
    "    strongly_con_comp = list(nx.strongly_connected_components(G))\n",
    "    strongly_con_comp = max(strongly_con_comp, key=len)\n",
    "\n",
    "    S = strongly_con_comp\n",
    "\n",
    "    v_any = list(S)[0]\n",
    "    DFS_G = set(nx.dfs_tree(G, v_any).nodes())\n",
    "    DFS_GT = set(nx.dfs_tree(GT, v_any).nodes())\n",
    "    OUT = DFS_G - S\n",
    "    IN = DFS_GT - S\n",
    "    V_rest = set(G.nodes()) - S - OUT - IN\n",
    "\n",
    "    TUBES = set()\n",
    "    INTENDRILS = set()\n",
    "    OUTTENDRILS = set()\n",
    "    OTHER = set()\n",
    "    for v in V_rest:\n",
    "        irv = len(IN & set(nx.dfs_tree(GT, v).nodes())) != 0\n",
    "        vro = len(OUT & set(nx.dfs_tree(G, v).nodes())) != 0\n",
    "        if irv and vro:\n",
    "            TUBES.add(v)\n",
    "        elif irv and not vro:\n",
    "            INTENDRILS.add(v)\n",
    "        elif not irv and vro:\n",
    "            OUTTENDRILS.add(v)\n",
    "        elif not irv and not vro:\n",
    "            OTHER.add(v)\n",
    "\n",
    "    return S, IN, OUT, TUBES, INTENDRILS, OUTTENDRILS, OTHER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC, IN, OUT, TUBES, INTENDRILS, OUTTENDRILS, OTHER = saveOrLoadFile(\n",
    "    \"bowtieComponents\", get_bowtie_components, {\"graph\": dataGraph}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netToSimp(network, data):\n",
    "    data = sorted(\n",
    "        data,\n",
    "        key=lambda dataPoint: str(dataPoint[\"Source\"])\n",
    "        + str(dataPoint[\"Target\"])\n",
    "        + str(dataPoint[\"Timeset\"])\n",
    "        + str(dataPoint[\"Weight\"])\n",
    "        + str(dataPoint[\"Contract\"]),\n",
    "    )\n",
    "    edges = sorted(\n",
    "        list(network.edges(data=True)),\n",
    "        key=lambda edge: str(edge[0])\n",
    "        + str(edge[1])\n",
    "        + str(edge[2][\"attr\"][\"Timeset\"])\n",
    "        + str(edge[2][\"attr\"][\"Weight\"])\n",
    "        + str(edge[2][\"attr\"][\"Contract\"]),\n",
    "    )\n",
    "    selectedData = [[]] * len(edges)\n",
    "    # print(len(edges))\n",
    "    i = 0\n",
    "    for dataPoint in data:\n",
    "        if (\n",
    "            edges[i][0] == dataPoint[\"Source\"]\n",
    "            and edges[i][1] == dataPoint[\"Target\"]\n",
    "            and edges[i][2][\"attr\"][\"Timeset\"] == dataPoint[\"Timeset\"]\n",
    "            and edges[i][2][\"attr\"][\"Weight\"] == dataPoint[\"Weight\"]\n",
    "            and edges[i][2][\"attr\"][\"Contract\"] == dataPoint[\"Contract\"]\n",
    "        ):\n",
    "            selectedData[i] = dataPoint\n",
    "            i += 1\n",
    "    return selectedData\n",
    "\n",
    "\n",
    "def filterByNodes(nodes, data, attrs, combine=False):\n",
    "    filteredData = data\n",
    "    operator = any if combine else all\n",
    "    filteredData = filter(lambda dataPoint: operator([dataPoint[attr] in nodes for attr in attrs]), filteredData)\n",
    "    return list(filteredData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getTimeData(data, attribute=None):\n",
    "#     timeData = {}\n",
    "\n",
    "#     def checkAndAdd(key, addValue=1):\n",
    "#         if key not in timeData:\n",
    "#             timeData[key] = 0\n",
    "#         timeData[key] += addValue\n",
    "\n",
    "#     for dataPoint in data:\n",
    "#         checkAndAdd(\n",
    "#             datetime.date(datetime.fromisoformat(dataPoint[\"Timeset\"])),\n",
    "#             1 if attribute is None else dataPoint[attribute],\n",
    "#         )\n",
    "\n",
    "#     return dict(sorted(timeData.items()))\n",
    "\n",
    "def getTimeData(data, attribute=None):\n",
    "    if len(data) == 0:\n",
    "        return {}\n",
    "    lastDate = datetime.date(\n",
    "        datetime.fromisoformat(\n",
    "            max(data, key=lambda dataPoint: dataPoint[\"Timeset\"])[\"Timeset\"]\n",
    "        )\n",
    "    )\n",
    "    firstDate = datetime.date(\n",
    "        datetime.fromisoformat(\n",
    "            min(data, key=lambda dataPoint: dataPoint[\"Timeset\"])[\"Timeset\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    timeData = {date.date(): 0 for date in pd.date_range(firstDate, lastDate)}\n",
    "\n",
    "    for dataPoint in data:\n",
    "        timeData[datetime.date(datetime.fromisoformat(dataPoint[\"Timeset\"]))] += (\n",
    "            1 if attribute is None else dataPoint[attribute]\n",
    "        )\n",
    "\n",
    "    return dict(sorted(timeData.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultTickMultiplier = 2 / 3\n",
    "defaultFigsize = (15, 5)\n",
    "defaultDpi = 150\n",
    "defaultTitle = \"Number of Transactions vs Date\"\n",
    "defaultYLabel = \"Number of Transactions\"\n",
    "defaultXLabel = \"Date\"\n",
    "graphFolder = \"./graphs/\"\n",
    "graphFileType = \".png\"\n",
    "\n",
    "\n",
    "def plotDateRange(\n",
    "    datas,\n",
    "    start=None,\n",
    "    end=None,\n",
    "    tickMultiplier=defaultTickMultiplier,\n",
    "    specialDates={},\n",
    "    figsize=defaultFigsize,\n",
    "    dpi=defaultDpi,\n",
    "    title=defaultTitle,\n",
    "    xlabel=defaultXLabel,\n",
    "    ylabel=defaultYLabel,\n",
    "    graphAttributes=[],\n",
    "):\n",
    "    def calcXticksAndLabels():\n",
    "        graphWidth = figsize[0]\n",
    "        previousDate = keysToUse[0]\n",
    "        totalTimeDelta = keysToUse[-1] - previousDate\n",
    "        specailDatesAndEnd = sorted(specialDates.keys())\n",
    "        specailDatesAndEnd.append(keysToUse[-1])\n",
    "        for specialDate in specailDatesAndEnd:\n",
    "            timeDelta = specialDate - previousDate\n",
    "            xticks.extend(\n",
    "                list(\n",
    "                    pd.date_range(\n",
    "                        previousDate,\n",
    "                        specialDate,\n",
    "                        math.floor(\n",
    "                            tickMultiplier * graphWidth * (timeDelta / totalTimeDelta)\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            xticks.append(specialDate)\n",
    "            previousDate = specialDate\n",
    "\n",
    "        for xtick in xticks:\n",
    "            if type(xtick) != type(datetime.now().date()):\n",
    "                xtick = xtick.date()\n",
    "            if xtick in specialDates and specialDates[xtick] is not None:\n",
    "                xtickLabels.append(specialDates[xtick] + \"\\n\" + str(xtick))\n",
    "            else:\n",
    "                xtickLabels.append(xtick)\n",
    "\n",
    "        return xticks, xtickLabels\n",
    "\n",
    "    def plot(keysToUseList, valuesToUseList, legend=None):\n",
    "        attributesString = \"\"\n",
    "        if len(graphAttributes) > 0:\n",
    "            attributesString = \" (\"\n",
    "            attributesString += graphAttributes[0]\n",
    "            for graphAttribute in graphAttributes[1:]:\n",
    "                attributesString += \", \" + graphAttribute\n",
    "            attributesString += \")\"\n",
    "\n",
    "        plt.figure(figsize=figsize, dpi=dpi)\n",
    "        for i in range(len(keysToUseList)):\n",
    "            plt.plot(keysToUseList[i], valuesToUseList[i])\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.title(title + attributesString)\n",
    "        plt.xticks(xticks, xtickLabels)\n",
    "        if legend is not None:\n",
    "            plt.legend(legend, title=\"Nodes Included\")\n",
    "        plt.savefig(\n",
    "            fname=graphFolder + title + attributesString + graphFileType,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    keysToUseList = []\n",
    "    valuesToUseList = []\n",
    "    xtickLabels = []\n",
    "    xticks = []\n",
    "    legend = []\n",
    "    graphAttributes.append(\"Placeholder\")\n",
    "    for filterName, filteredData in datas.items():\n",
    "        keyslist = list(filteredData.keys())\n",
    "        startIndex = bisect_left(keyslist, start) if start is not None else 0\n",
    "        endIndex = bisect_left(keyslist, end) if end is not None else len(keyslist)\n",
    "\n",
    "        keysToUse = keyslist[startIndex:endIndex]\n",
    "\n",
    "        if xticks == []:\n",
    "            xticks, xtickLabels = calcXticksAndLabels()\n",
    "\n",
    "        valueslist = list(filteredData.values())\n",
    "        valuesToUse = valueslist[startIndex:endIndex]\n",
    "        graphAttributes[-1] = filterName + \" Nodes\"\n",
    "        # print(valuesToUse)\n",
    "        plot([keysToUse], [valuesToUse])\n",
    "        valuesToUseList.append(valuesToUse)\n",
    "        keysToUseList.append(keysToUse)\n",
    "        legend.append(filterName)\n",
    "\n",
    "    graphAttributes = graphAttributes[:-1]\n",
    "    plot(keysToUseList, valuesToUseList, legend)\n",
    "\n",
    "\n",
    "def plotAroundDate(center, startDist=30, endDist=None, **plotParams):\n",
    "    endDist = startDist if endDist is None else endDist\n",
    "    plotParams[\"start\"] = center - timedelta(startDist)\n",
    "    plotParams[\"end\"] = center + timedelta(endDist)\n",
    "    plotDateRange(**plotParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(data, events, filters, attributes, zooms, titleAddition=\"\"):\n",
    "    timeDatas = {}\n",
    "    for filterName, filterNodes, filterAttributes in filters:\n",
    "        # print(filterAttributes)\n",
    "        filteredData = filterByNodes(filterNodes, data, filterAttributes)\n",
    "        for attributeName, attribute in attributes:\n",
    "            if attributeName not in timeDatas:\n",
    "                timeDatas[attributeName] = {}\n",
    "            timeDatas[attributeName][filterName] = getTimeData(filteredData, attribute)\n",
    "\n",
    "    for attributeName, filteredDatas in timeDatas.items():\n",
    "        for eventDate, eventName in events.items():\n",
    "            graphAttributes = [str(eventDate), \"Weighted by \" + attributeName]\n",
    "            eventNameSingleLine = eventName.replace(\"\\n\", \"\")\n",
    "            for zoom in zooms:\n",
    "                plotAroundDate(\n",
    "                    center=eventDate,\n",
    "                    startDist=zoom,\n",
    "                    endDist=zoom,\n",
    "                    datas=filteredDatas,\n",
    "                    specialDates={eventDate: eventName},\n",
    "                    ylabel=attributeName,\n",
    "                    title=str(zoom)\n",
    "                    + \" Day Zoom of the \"\n",
    "                    + \"Effect of \"\n",
    "                    + eventNameSingleLine\n",
    "                    + titleAddition,\n",
    "                    graphAttributes=graphAttributes,\n",
    "                )\n",
    "        plotDateRange(\n",
    "            filteredDatas,\n",
    "            specialDates=events,\n",
    "            figsize=(200, 10),\n",
    "            ylabel=attributeName,\n",
    "            graphAttributes=graphAttributes,\n",
    "            title=defaultTitle + titleAddition\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = {\n",
    "    datetime(2021, 5, 3).date(): \"ZEPETO\",\n",
    "    datetime(2022, 9, 9).date(): \"Atari\",\n",
    "    datetime(2022, 11, 11).date(): \"Care Bears\",\n",
    "    datetime(2020, 10, 29).date(): \"The Smurfs\",\n",
    "    datetime(2022, 7, 19).date(): \"Steve Aoki\",\n",
    "    datetime(2021, 10, 29).date(): \"deadmau5\",\n",
    "    datetime(2021, 12, 15).date(): \"Adidas\",\n",
    "    datetime(2021, 9, 23).date(): \"Snoop Dogg\",\n",
    "    datetime(2021, 7, 8).date(): \"The Walking Dead\",\n",
    "    datetime(2022, 10, 28).date(): \"Gucci Vault\",\n",
    "    datetime(2022, 2, 8).date(): \"Ubisoft\",\n",
    "    datetime(2022, 1, 27).date(): \"Warner Music Group\",\n",
    "    datetime(2022, 2, 28).date(): \"Square Enix\",\n",
    "    datetime(2023, 5, 26).date(): \"CEO's Twitter \\nHacked\",\n",
    "    datetime(2023, 2, 26).date(): \"Computer Hacked to \\nSend Phishing Emails\",\n",
    "    datetime(2023, 6, 6).date(): \"SEC Naming \\nSAND as Unregistered \\nSecurity\",\n",
    "    datetime(2022, 3, 23).date(): \"Ronin Hack\",\n",
    "    datetime(2023, 1, 18).date(): \"Lunar New Year Event\",\n",
    "}\n",
    "\n",
    "filters = [\n",
    "    (\"ALL\", {}, []),\n",
    "    (\"IN\", IN, [\"Source\"]),\n",
    "    (\"OUT\", OUT, [\"Target\"]),\n",
    "    (\"SCC\", SCC, [\"Source\", \"Target\"]),\n",
    "]\n",
    "\n",
    "attributes = [\n",
    "    (\"Number of Transactions\", None),\n",
    "    (\"Value of Transactions\", \"Weight\"),\n",
    "]\n",
    "\n",
    "zooms = [30, 90]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Transactions: 4948956\n",
      "Number of Addresses: 659248\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Transactions: \" + str(len(simplifiedData)))\n",
    "print(\"Number of Addresses: \" + str(len(set([d[\"Source\"] for d in simplifiedData] + [d[\"Target\"] for d in simplifiedData]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(simplifiedData, events, filters, attributes, zooms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWhales(data, minValue=1e22, numberOfWhales=-1):\n",
    "    def checkAndAdd(address, value):\n",
    "        if address not in addresses:\n",
    "            addresses[address] = 0\n",
    "        addresses[address] += value\n",
    "    def checkAndSupplant(address):\n",
    "        if address not in maxAddresses:\n",
    "            maxAddresses[address] = addresses[address]\n",
    "        elif maxAddresses[address] < addresses[address]:\n",
    "            maxAddresses[address] = addresses[address]\n",
    "\n",
    "\n",
    "    addresses = {}\n",
    "    maxAddresses = {}\n",
    "    for dataPoint in data:\n",
    "        checkAndAdd(dataPoint[\"Source\"], -dataPoint[\"Weight\"])\n",
    "        checkAndAdd(dataPoint[\"Target\"], dataPoint[\"Weight\"])\n",
    "        checkAndSupplant(dataPoint[\"Source\"])\n",
    "        checkAndSupplant(dataPoint[\"Target\"])\n",
    "\n",
    "    whales = set(\n",
    "        [\n",
    "            whale\n",
    "            for whale, value in sorted(\n",
    "                filter(lambda address: address[1] > minValue, addresses.items()),\n",
    "                key=lambda address: address[1],\n",
    "                reverse=True,\n",
    "            )[:numberOfWhales]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    maxWhales = set(\n",
    "        [\n",
    "            whale\n",
    "            for whale, value in sorted(\n",
    "                filter(lambda address: address[1] > minValue, maxAddresses.items()),\n",
    "                key=lambda address: address[1],\n",
    "                reverse=True,\n",
    "            )[:numberOfWhales]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return whales, maxWhales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "whales, maxWhales = getWhales(filterSimplifiedData(simplifiedData, contract=\"0x3845badade8e6dff049820680d1f14bd3903a5d0\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Whales: 2464\n",
      "All Whales Over Time: 33758\n",
      "Current Whales in SCC: 890\n",
      "All Whales Over Time in SCC: 32174\n",
      "Current Whales in OUT: 1574\n",
      "All Whales Over Time in OUT: 1584\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Whales: \" + str(len(whales)) + \"\\nAll Whales Over Time: \" + str(len(maxWhales)))\n",
    "print(\"Current Whales in SCC: \" + str(sum([whale in SCC for whale in whales])) + \"\\nAll Whales Over Time in SCC: \" + str(sum([whale in SCC for whale in maxWhales])))\n",
    "print(\"Current Whales in OUT: \" + str(sum([whale in OUT for whale in whales])) + \"\\nAll Whales Over Time in OUT: \" + str(sum([whale in OUT for whale in maxWhales])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(filterByNodes(whales, simplifiedData, [\"Source\", \"Target\"], combine=True), events, filters, attributes, zooms, titleAddition=\" On Current Whales\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(filterByNodes(whales, simplifiedData, [\"Target\"], combine=True), events, filters, attributes, zooms, titleAddition=\" On Current Whales Investing More\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(filterByNodes(whales, simplifiedData, [\"Source\"], combine=True), events, filters, attributes, zooms, titleAddition=\" On Current Whales Investing Less\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(filterByNodes(maxWhales, simplifiedData, [\"Source\", \"Target\"], combine=True), events, filters, attributes, zooms, titleAddition=\" On All Whales Over Time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(filterByNodes(maxWhales, simplifiedData, [\"Target\"], combine=True), events, filters, attributes, zooms, titleAddition=\" On All Whales Over Time Investing More\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plotData(filterByNodes(maxWhales, simplifiedData, [\"Source\"], combine=True), events, filters, attributes, zooms, titleAddition=\" On All Whales Over Time Investing Less\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gameFiResearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
