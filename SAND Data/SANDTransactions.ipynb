{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.api import request\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "previousRequestsBackupPath = \"./previousRequests/\"\n",
    "\n",
    "def get_valid_filename(name):\n",
    "    s = str(name).strip().replace(\" \", \"_\")\n",
    "    s = re.sub(r\"(?u)[^-\\w.]\", \"\", s)\n",
    "    if s in {\"\", \".\", \"..\"}:\n",
    "        return \"ErrorFileName\" + str(random.randrange(100000))\n",
    "    return s\n",
    "\n",
    "def get_valid_path(path):\n",
    "    s = str(path).strip().replace(\" \", \"_\")\n",
    "    s = re.sub(r\"(?u)[^-\\w./]\", \"\", s)\n",
    "    if s in {\"\", \".\", \"..\"}:\n",
    "        return \"ErrorFileName\" + str(random.randrange(100000))\n",
    "    return s\n",
    "\n",
    "def dumpAPIRequest(fileName, data, path=\"./previousRequests/\"):\n",
    "    fullFileName = get_valid_path(path) + get_valid_filename(fileName) + \".bin\"\n",
    "    os.makedirs(os.path.dirname(fullFileName), exist_ok=True)\n",
    "    with open(fullFileName, \"wb\") as outputFile:\n",
    "        pickle.dump(data, outputFile)\n",
    "    return fullFileName\n",
    "\n",
    "def loadAPIRequest(fileName):\n",
    "    fullFileName = previousRequestsBackupPath + get_valid_filename(fileName) +\".bin\"\n",
    "    if not os.path.exists(fullFileName):\n",
    "        return {}\n",
    "    with open(fullFileName, \"rb\") as inputFile:\n",
    "        data = pickle.load(inputFile)\n",
    "    return data[\"result\"]\n",
    "\n",
    "def checkForAPIRequest(url):\n",
    "    return os.path.exists(previousRequestsBackupPath + get_valid_filename(url) +\".bin\")\n",
    "\n",
    "def dumpJSON(fileName, data, path=\"./\"):\n",
    "    fullFileName = get_valid_path(path) + get_valid_filename(fileName) + \".json\"\n",
    "    os.makedirs(os.path.dirname(fullFileName), exist_ok=True)\n",
    "    with open(fullFileName, \"w\") as outputFile:\n",
    "        json.dump(data, outputFile, indent = 6)\n",
    "    return fullFileName\n",
    "\n",
    "def loadJSON(fullFileName):\n",
    "    if not os.path.exists(fullFileName):\n",
    "        return {}\n",
    "    with open(fullFileName, \"r\") as inputFile:\n",
    "        data = json.load(inputFile)\n",
    "    return data\n",
    "\n",
    "def checkForJSON(fileName, path):\n",
    "    fullFileName = get_valid_path(path) + get_valid_filename(fileName) + \".json\"\n",
    "    return loadJSON(fullFileName) if os.path.exists(fullFileName) else {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastRequestTime = 0\n",
    "personalAccessToken = \"116X4PZSFPNP2AHJGQK3S85REGS81HQFN2\"\n",
    "\n",
    "def apiRequest(url):\n",
    "    if checkForAPIRequest(url):\n",
    "        return loadAPIRequest(url)\n",
    "    \n",
    "    global lastRequestTime\n",
    "    while(time.time() < lastRequestTime+0.2):\n",
    "        pass\n",
    "    lastRequestTime = time.time()\n",
    "\n",
    "    response = requests.get(url + \"&apikey=\" + personalAccessToken)\n",
    "    data = response.json() if response.ok else {}\n",
    "\n",
    "    dumpAPIRequest(url, data)\n",
    "\n",
    "    return data[\"result\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiString = \"https://api.etherscan.io/api\"\n",
    "\n",
    "def getAllResults(url, backupName=None):\n",
    "    endBlock = \"18432623\"\n",
    "    startBlock = \"0\"\n",
    "    maxAmount = 10000\n",
    "    url = url + \"&endblock=\" + endBlock + \"&startblock=\"\n",
    "    singleList = apiRequest(url + str(startBlock))\n",
    "    all = singleList\n",
    "    dumpMultiplier = 1\n",
    "    while(len(singleList) >= maxAmount):\n",
    "        if(len(all) > 100000 * dumpMultiplier):\n",
    "            dumpJSON(backupName if backupName is not None else url, all, \"./tokenData/Backups/\")\n",
    "            dumpMultiplier += 1\n",
    "        lastElement = singleList[-1]\n",
    "        startBlock = lastElement[\"blockNumber\"]\n",
    "        offset = len(singleList) - next((i for i, item in enumerate(singleList) if item[\"blockNumber\"] == startBlock))\n",
    "        singleList = apiRequest(url + str(startBlock))\n",
    "        truncatedSingleList = singleList[offset:]\n",
    "        if(len(truncatedSingleList) > 0):\n",
    "            all += truncatedSingleList\n",
    "    return all\n",
    "\n",
    "moduleString = \"module=\"\n",
    "accountModuleString = moduleString + \"account\"\n",
    "actionString = \"action=\"\n",
    "tokenTxActionString = actionString + \"tokentx\"\n",
    "contractAdressString = \"contractaddress=\"\n",
    "def getTokenTransactions(address):\n",
    "    dumpJSON(address, getAllResults(apiString + \"?\" + accountModuleString + \"&\" + tokenTxActionString + \"&\" + contractAdressString + address, address), \"./tokenData/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenAddresses = [\"0x3845badAde8e6dFF049820680d1F14bD3903a5d0\"]\n",
    "\n",
    "for tokenAddress in tokenAddresses:\n",
    "    getTokenTransactions(tokenAddress)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gameFiResearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
